{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project Report\"\n",
    "subtitle: The Yelpers\n",
    "author: Michael Kim, Cindy Wu, Keaton Olds, Sabrina Kozarovitsky\n",
    "date: 03/14/2023\n",
    "number-sections: true\n",
    "abstract: _The ABSTRACT is to be in fully-justified italicized text at the top of the report, below the author information. The abstract section must summarise the problem statement, the developed model(s), the metric(s) optimized and the recommendations to the stakeholders based on the model. You may also briefly mention any major EDA-based insights that helped develop the model or directly translated into recommendations to the stakeholders. However, the abstract must not be more than 200 words in length_.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    self-contained: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba5ee91",
   "metadata": {},
   "source": [
    "## Length of the report {-}\n",
    "The length of the report must be no more than 15 pages, when printed as PDF. However, there is no requirement on the minimum number of pages.\n",
    "\n",
    "You may put additional stuff as Appendix. You may refer to the Appendix in the main report to support your arguments. However, your appendix is unlikely to be checked while grading, unless the grader deems it necessary. The appendix, references, and information about GitHub and individual contribution will not be included in the page count, and there is no limit on the length of the appendix.\n",
    "\n",
    "**Delete this section from the report, when using this template.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3d9ed",
   "metadata": {},
   "source": [
    "## Code should be put separately in the code template {-}\n",
    "Your report should be in a research-paper like style. If there is something that can only be explained by showing the code, then you may put it, otherwise do not put the code in the report. We will check your code in the code template. \n",
    "\n",
    "**Delete this section from the report, when using this template.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Background / Motivation\n",
    "\n",
    "What motivated you to work on this problem?\n",
    "\n",
    "Mention any background about the problem, if it is required to understand your analysis later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5d5c7",
   "metadata": {},
   "source": [
    "As avid Uber/Lyft riders ourselves, we were naturally drawn to the question of how Ubers/Lyfts are priced -- and which factors contribute most to the pricing of these rides. It comes up a lot in our daily lives, and we wanted to take this as an opportunity to explore this subject more deeply. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff1421",
   "metadata": {},
   "source": [
    "## Problem statement \n",
    "\n",
    "Describe your problem statement. Articulate your objectives using absolutely no jargon. Interpret the problem as inference and/or prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae677f",
   "metadata": {},
   "source": [
    "For this project, we wanted to undestand how certain ride factors (ex. distance of the trip, timestamp, weather, destination, etc.) relate to the price of a ride. Since our response variable (price of the ride) is continuous, this is a regression problem. Our project incoprorated both prediction and inference. One the one hand, we wanted to be able to build a model to predict the price of rides. In addition, we wanted to figure out which factors had the largest impact on price, which has to do with inference.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7b95f",
   "metadata": {},
   "source": [
    "## Data sources\n",
    "What data did you use? Provide details about your data. Include links to data if you are using open-access data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3961c3",
   "metadata": {},
   "source": [
    "We used the “Uber & Lyft Cab prices” dataset on Kaggle (https://www.kaggle.com/datasets/ravi72munde/uber-lyft-cab-prices). The dataset includes information on ride prices (collected for a week in November - December 2018) as well as relevant information such as the distance of the trip, timestamp, weather, and destination. We used these factors to help us predict the price of the ride – and determine which factors seem to have a larger effect on price than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c255035",
   "metadata": {},
   "source": [
    "## Stakeholders\n",
    "Who cares? If you are successful, what difference will it make to them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c5b15d",
   "metadata": {},
   "source": [
    "We had 3 primary stakeholders:\n",
    "\n",
    "1) Taxi Company and Drivers: they are competitors with Uber/Lyft when it comes to the rideshare market. Through using our model, they can understand rideshare pricing better and adjust accordingly to gain a competitive edge during certain times\n",
    "\n",
    "2) Uber and Lyft Users: people who use Uber/Lyft can use our model to understand when to use rideshare versus other transportation and use this information to plan ahead around high price times to save money\n",
    "\n",
    "3) Uber and Lyft Drivers: as they are direct employees of Uber/Lyft and their salary is directly related to the price of the rides, they are large stakeholders. Through using our model, they can better understand how rides are priced, gauge their expected earnings for a given ride, and have more autonomy over their revenue (ex. choose to take rides during high price times)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data quality check / cleaning / preparation \n",
    "\n",
    "In a tabular form, show the distribution of values of each variable used in the analysis - for both categorical and continuous variables. Distribution of a categorical variable must include the number of missing values, the number of unique values, the frequency of all its levels. If a categorical variable has too many levels, you may just include the counts of the top 3-5 levels. \n",
    "\n",
    "If the tables in this section take too much space, you may put them in the appendix, and just mention any useful insights you obtained from the data quality check that helped you develop the model or helped you realize the necessary data cleaning / preparation.\n",
    "\n",
    "Were there any potentially incorrect values of variables that required cleaning? If yes, how did you clean them? \n",
    "\n",
    "Did you do any data wrangling or data preparation before the data was ready to use for model development? Did you create any new predictors from exisiting predictors? For example, if you have number of transactions and spend in a credit card dataset, you may create spend per transaction for predicting if a customer pays their credit card bill. Mention the steps at a broad level, you may put minor details in the appendix. Only mention the steps that ended up being useful towards developing your final model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd74a9",
   "metadata": {},
   "source": [
    "Put the relevant EDA here (visualizations, tables, etc.) that helped you figure out useful predictors for developing the model(s). Only put the EDA that ended up being useful towards developing your final model(s). \n",
    "\n",
    "List the insights (as bullet points) you got from EDA that ended up being useful towards developing your final model. \n",
    "\n",
    "Again, if there are too many plots / tables, you may put them into appendix, and just mention the insights you got from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "What kind of a model (linear / logistic / other) did you use? What performance metric(s) did you optimize and why?\n",
    "\n",
    "Is there anything unorthodox / new in your approach? \n",
    "\n",
    "What problems did you anticipate? What problems did you encounter? Did the very first model you tried work? \n",
    "\n",
    "Did your problem already have solution(s) (posted on Kaggle or elsewhere). If yes, then how did you build upon those solutions, what did you do differently? Is your model better as compared to those solutions in terms of prediction / inference?\n",
    "\n",
    "**Important: Mention any code repositories (with citations) or other sources that you used, and specifically what changes you made to them for your project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a8c736",
   "metadata": {},
   "source": [
    "The model that we used was an initial single linear regression model, several multiple linear regression models, and finally a lasso regression model. We decided to optimize for the performance metric of RMSE. We did this because we wanted to penalize large errors, since large errors could mean that the customer ends up paying a much higher price than they were expecting if using our model to try and predict the ride price (which could be an undue, large financial strain for them). Therefore, since RMSE properly penalizes these large errors versus other options like MAE (which equally penalizes the error from each observation), we will proceed with utilizing this performance metric to optimize. \n",
    "\n",
    "There was nothing too unorthodox or new in our approach. We decided to start with a base/naive model with what we thought would be the singlemost important predictor (distance), and then we moved onto using all of the predictors in the dataset and the new predictor variables that we created to get new multiple linear regression models. Lastly, we used a lasso regression model considering all of the previously used predictor variables and all possible two-factor interactions as predictors. We decided to use a lasso regression model because doing so could be used for variable selection and could handle the presence of stronger correlated features that existed in the dataset. XXXXXXX *better reason for lasso* XXXXXXX. \n",
    "\n",
    "We anticipated problems when it came to preparing the actual data that allowed us to go about our approach. Specifically, there was only select weather data available for various source and destination locations on specific dates and at specific times. As such, we did in fact encounter this problem when approaching how to best clean and prepare the data itself before going about developing our models. Additionally, we anticipated the problem of multicollinearity when it came to the dummy variables we were going to create on the type of ride and with weather variables. XXXXXX (did we encounter this problem) XXXXXX. Lastly, we wanted to potentially focus on autocorrelation as a possible problem we anticipated and wanted to explore in our data further. The first model that we tried including our created variables and the weather variables only had a slight improvement compared with the base/naive model of all the ride dataset variables. \n",
    "\n",
    "Our problem did already have some solutions posted on Kaggle trying to predict the ride price of Uber/Lyft rides in the same datasets. The one solution of these that we did look at closer decided to approach the problem we encountered with data cleaning/preparation of the weather variables by averaging them out for each source and destination location. After further analysis, we decided that this wouldn't be the best approach, since the average rainfall, cloud coverage, etc. of a given location isn't what we wanted to examine as predictors. Instead, we wanted accurate weather information of an actual given time for a location, which is why we took the steps we did to clean the data and get only the observations that had said weather data for locations at specific times. Further, this solution did not handle the potential issues with multicollinearity or exploration of autocorrelation, which we decided to analyze to build upon this solution. While this model only ended up analyzing R-squared as a performance metric, we do believe that our model was better compared to this solution. Although we cannot compare by RMSE, the solution's model does little to build upon the multiple linear regression model RMSE with all the train and weather predictor variables, and as such, we believe that our lasso regression model does in fact do better when compared to this solution. Additionally, since this solution's model does not handle the possibility of multicollinearity, we believe that our final model is better since we have confirmed that no problematic amounts of multicollinearity exist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec4c9",
   "metadata": {},
   "source": [
    "Explain the steps taken to develop and improve the base model - informative visualizations / addressing modeling assumption violations / variable transformation / interactions / outlier treatment / influential points treatment / addressing over-fitting / addressing multicollinearity / variable selection - stepwise regression, lasso, ridge regression). \n",
    "\n",
    "Did you succeed in achieving your goal, or did you fail? Why?\n",
    "\n",
    "**Put the final model equation**.\n",
    "\n",
    "**Important: This section should be rigorous and thorough. Present detailed information about decision you made, why you made them, and any evidence/experimentation to back them up.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6463bad",
   "metadata": {},
   "source": [
    "The base model was created as a single linear regression model using distance as the only predictor variable and price as the response variable. The resulting RMSE of the model was approximately XXXXXXXX *fill in RMSE* XXXXXXXXXXXXXX. The mean for the price of the cleaned data observations was approximately XXXXXXXX *fill in mean* XXXXXXXXXX and the standard error was approximately XXXXXXXX *fill in standard error* XXXXXXXXXXX. We decided to make a better base model as a multiple linear regression model using all of the variables from the ride dataset as predictor variables (including X, Y, Z, etc.). We made this decision because we felt that it would be a better representation of comparison for our efforts in improving the base model. \n",
    "\n",
    "From this, we examined the predictor variables for potential variable transformations that would be helpful in improving model performance as measured by RMSE. Ultimately, we discovered one possible non-linear relationship between distance and price from a barplot of price against binned distance (with the price increasing slightly more as binned distance increased). As such, we decided it would be prudent to examine whether a log(distance) transformation would improve RMSE if included in a model (which it ended up doing). \n",
    "\n",
    "Next, we decided to examine whether this base multiple linear regression model also violated any modeling assumptions. Specifically, we did so MODELING ASSUMPTION\n",
    "\n",
    "VARIABLE SELECTION - LASSO REGRESSION -> INTERACTIONS\n",
    "\n",
    "OUTLIERS/INFLUENTIAL POINTS\n",
    "\n",
    "OVERFITTING?\n",
    "\n",
    "MULTICOLLINEARITY?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46343d",
   "metadata": {},
   "source": [
    "## Limitations of the model with regard to inference / prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ead90",
   "metadata": {},
   "source": [
    "If it is inference, will the inference hold for a certain period of time, for a certain subset of population, and / or for certain conditions.\n",
    "\n",
    "If it is prediction, then will it be possible / convenient / expensive for the stakeholders to collect the data relating to the predictors in the model. Using your model, how soon will the stakeholder be able to predict the outcome before the outcome occurs. For example, if the model predicts the number of bikes people will rent in Evanston on a certain day, then how many days before that day will your model be able to make the prediction. This will depend on how soon the data that your model uses becomes available. If you are predicting election results, how many days / weeks / months / years before the election can you predict the results. \n",
    "\n",
    "When will your model become too obsolete to be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c955e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6026cb7",
   "metadata": {},
   "source": [
    "## Other sections *(optional)*\n",
    "\n",
    "You are welcome to introduce additional sections or subsections, if required, to address any specific aspects of your project in detail. For example, you may briefly discuss potential future work that the research community could focus on to make further progress in the direction of your project's topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations to stakeholder(s)\n",
    "\n",
    "What conclusions do you draw based on your model? If it is inference you may draw conclusions based on the coefficients, statistical significance of predictors / interactions, etc. If it is prediction, you may draw conclusions based on prediction accuracy, or other performance metrics.\n",
    "\n",
    "How do you use those conclusions to come up with meaningful recommendations for stakeholders? The recommendations must be action-items for stakeholders that they can directly implement without any further analysis. Be as precise as possible. The stakeholder(s) are depending on you to come up with practically implementable recommendations, instead of having to think for themselves.\n",
    "\n",
    "If your recommendations are not practically implementable by stakeholders, how will they help them? Is there some additional data / analysis / domain expertise you need to do to make the recommendations implementable? \n",
    "\n",
    "Do the stakeholder(s) need to be aware about some limitations of your model? Is your model only good for one-time use, or is it possible to update your model at a certain frequency (based on recent data) to keep using it in the future? If it can be used in the future, then for how far into the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c44497c",
   "metadata": {},
   "source": [
    "## GitHub and individual contribution {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b3f66",
   "metadata": {},
   "source": [
    "Put the **Github link** for the project repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca45613",
   "metadata": {},
   "source": [
    "Add details of each team member's contribution in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505da5c",
   "metadata": {},
   "source": [
    "<html>\n",
    "<style>\n",
    "table, td, th {\n",
    "  border: 1px solid black;\n",
    "}\n",
    "\n",
    "table {\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "th {\n",
    "  text-align: left;\n",
    "}\n",
    "    \n",
    "\n",
    "</style>\n",
    "<body>\n",
    "\n",
    "<h2>Individual contribution</h2>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "     <colgroup>\n",
    "       <col span=\"1\" style=\"width: 15%;\">\n",
    "       <col span=\"1\" style=\"width: 20%;\">\n",
    "       <col span=\"1\" style=\"width: 50%;\">\n",
    "       <col span=\"1\" style=\"width: 15%;\"> \n",
    "    </colgroup>\n",
    "  <tr>\n",
    "    <th>Team member</th>\n",
    "    <th>Contributed aspects</th>\n",
    "    <th>Details</th>\n",
    "    <th>Number of GitHub commits</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Elton John</td>\n",
    "    <td>Data cleaning and EDA</td>\n",
    "    <td>Cleaned data to impute missing values and developed visualizations to identify appropriate variable transformations.</td>\n",
    "    <td>100</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Xena Valenzuela</td>\n",
    "    <td>Assumptions and interactions</td>\n",
    "    <td>Checked and addressed modeling assumptions and identified relevant variable interactions.</td>\n",
    "    <td>120</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Sankaranarayanan Balasubramanian</td>\n",
    "    <td>Outlier and influential points treatment</td>\n",
    "    <td>Identified outliers/influential points and analayzed their effect on the model.</td>\n",
    "    <td>130</td>    \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Chun-Li</td>\n",
    "    <td>Variable selection and addressing overfitting</td>\n",
    "    <td>Performed variable selection on an exhaustive set of predictors to address multicollinearity and overfitting.</td>\n",
    "    <td>150</td>    \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192bbd23",
   "metadata": {},
   "source": [
    "List the **challenges** you faced when collaborating with the team on GitHub. Are you comfortable using GitHub? \n",
    "Do you feel GitHuB made collaboration easier? If not, then why? *(Individual team members can put their opinion separately, if different from the rest of the team)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1cafe",
   "metadata": {},
   "source": [
    "## References {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb1aad",
   "metadata": {},
   "source": [
    "List and number all bibliographical references. When referenced in the text, enclose the citation number in square brackets, for example [1].\n",
    "\n",
    "[1] Authors. The frobnicatable foo filter, 2014. Face and Gesture submission ID 324. Supplied as additional material\n",
    "fg324.pdf. 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831751c",
   "metadata": {},
   "source": [
    "## Appendix {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d374d",
   "metadata": {},
   "source": [
    "You may put additional stuff here as Appendix. You may refer to the Appendix in the main report to support your arguments. However, the appendix section is unlikely to be checked while grading, unless the grader deems it necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
